@unpublished{arreghini2022exploring,
  author = {Simone Arreghini and Cristina Iani and Alessandro Giusti and Valeria Villani and Lorenzo Sabattini and Antonio Paolillo},
  title  = {Exploring Human-Robot Collaboration: Analysis of Interaction Modalities in Challenging Tasks},
  note   = {Unpublished manuscript. PDF accessed by personal communication.},
  year   = {2022}
}

@misc{frovaaa2025robomaster,
  author       = {Davide Frova},
  title        = {robomaster\_ros: {ROS2} drivers for RoboMaster {EP}},
  howpublished = {\url{https://github.com/frovaaa/robomaster_ros}},
  note         = {Fork of original codebase, expanded for this project},
  year         = {2025}
}

@misc{frovaaa2025robomasterhri,
  author       = {Davide Frova},
  title        = {robomaster\_hri: {ROS2} packages for Human-Robot Interaction with RoboMaster {EP}},
  howpublished = {\url{https://github.com/frovaaa/robomaster_hri}},
  note         = {Private repository. Fork of original codebase, expanded for navigation and interaction in HRI experiments},
  year         = {2025}
}

@misc{foxglove,
  author       = {Foxglove Technologies, Inc.},
  title        = {Foxglove Studio},
  howpublished = {\url{https://foxglove.dev}},
  note         = {Accessed: 2025-05-21}
}

@misc{rviz2,
  author       = {{Open Source Robotics Foundation}},
  title        = {{RViz2}},
  howpublished = {\url{https://github.com/ros2/rviz}},
  note         = {Accessed: 2025-06-12}
}

@misc{djirobomasterep,
  author       = {DJI},
  title        = {RoboMaster {EP}},
  howpublished = {\url{https://www.dji.com/ch/robomaster-ep/specs}},
  note         = {Accessed: 2025-05-21}
}

@misc{frovaaa2025hogwarts,
  author       = {Davide Frova},
  title        = {{H.O.G.W.A.R.T.S} -- Human Operated GUI for Wizardry and Remote Telepresence System},
  howpublished = {\url{https://github.com/frovaaa/hogwarts}},
  note         = {Web-based dashboard for Wizard-of-Oz control},
  year         = {2025}
}

@unpublished{landoni2025tesoro,
  author = {Monica Landoni and Antonio Paolillo},
  title  = {{TESORO}: {TEaching SOcial RObots to help children learn about themselves. SNSF Project Proposal}},
  note   = {Unpublished project proposal, shared via personal communication},
  year   = {2025}
}

@misc{roslibjs,
  author       = {{Robot Web Tools}},
  title        = {roslibjs},
  howpublished = {\url{https://github.com/RobotWebTools/roslibjs}},
  note         = {Accessed: 2025-05-21}
}

@misc{rosbridge,
  author       = {{Robot Web Tools}},
  title        = {rosbridge\_server},
  howpublished = {\url{https://github.com/RobotWebTools/rosbridge_suite/tree/ros2/rosbridge_server}},
  note         = {Accessed: 2025-05-21}
}

@misc{rclnodejs,
  author       = {{Robot Web Tools}},
  title        = {rclnodejs},
  howpublished = {\url{https://github.com/RobotWebTools/rclnodejs}},
  note         = {Accessed: 2025-05-21}
}

@misc{ros2,
  author       = {{Open Source Robotics Foundation}},
  title        = {{Robot Operating System 2 (ROS 2)}},
  howpublished = {\url{https://www.ros.org}},
  note         = {Accessed: 2025-05-21}
}

@article{doi:10.1126/scirobotics.abm6074,
  author  = {Steven Macenski and Tully Foote and Brian Gerkey and Chris Lalancette and William Woodall},
  title   = {Robot Operating System 2: Design, architecture, and uses in the wild},
  journal = {Science Robotics},
  volume  = {7},
  number  = {66},
  pages   = {eabm6074},
  year    = {2022},
  doi     = {10.1126/scirobotics.abm6074},
  url     = {https://www.science.org/doi/abs/10.1126/scirobotics.abm6074}
}

@article{biswas2005learning,
  author  = {Gautam Biswas and Krittaya Leelawong and Daniel Schwartz and Nancy Vye and The Teachable Agents Group at Vanderbilt},
  title   = {Learning by teaching: A new agent paradigm for educational software},
  journal = {Applied Artificial Intelligence},
  volume  = {19},
  number  = {3-4},
  pages   = {363--392},
  year    = {2005},
  doi     = {10.1080/08839510590910200},
  url     = {https://doi.org/10.1080/08839510590910200}
}

@article{10.5898/JHRI.1.1.Tanaka,
  author     = {Tanaka, Fumihide and Matsuzoe, Shizuko},
  title      = {Children teach a care-receiving robot to promote their learning: field experiments in a classroom for vocabulary learning},
  year       = {2012},
  issue_date = {July 2012},
  publisher  = {Journal of Human-Robot Interaction Steering Committee},
  volume     = {1},
  number     = {1},
  url        = {https://doi.org/10.5898/JHRI.1.1.Tanaka},
  doi        = {10.5898/JHRI.1.1.Tanaka},
  abstract   = {In contrast to conventional teaching agents (including robots) that were designed to play the role of human teachers or caregivers, we propose the opposite scenario in which robots receive instruction or care from children. We hypothesize that by using this care-receiving robot, we may construct a new educational framework whose goal is to promote children's spontaneous learning by teaching through their teaching the robot. In this paper, we describe the introduction of a care-receiving robot into a classroom at an English language school for Japanese children (3--6 years of age) and then conduct an experiment to evaluate if the care-receiving robot can promote their learning using English verbs. The results suggest that the idea of a care-receiving robot is feasible and that the robot can help children learn new English verbs efficiently. In addition, we report on investigations into several forms of teaching performed by children, which were revealed through observations of the children, parent interviews, and other useful knowledge. These can be used to improve the design of care-receiving robots for educational purposes.},
  journal    = {J. Hum.-Robot Interact.},
  month      = jul,
  pages      = {78-95},
  numpages   = {18},
  keywords   = {NAO, care-receiving robot, child-robot interaction, direct teaching, early childhood education, learning by teaching, learning support, robot ethics, teachable robot}
}

@article{osti_10386132,
  place        = {Country unknown/Code not available},
  title        = {Robots for Connection: A Co-Design Study with Adolescents},
  year         = {2022},
  url          = {https://par.nsf.gov/biblio/10386132},
  doi          = {10.1109/ro-man53752.2022.9900534},
  abstractnote = {Adolescents isolated at home during the COVID19 pandemic lockdown are more likely to feel lonely and in need of social connection. Social robots may provide a much needed social interaction without the risk of contracting an infection. In this paper, we detail our co-design process used to engage adolescents in the design of a social robot prototype intended to broadly support their mental health. Data gathered from our four week design study of nine remote sessions and interviews with 16 adolescents suggested the following design requirements for a home robot: (1) be able to enact a set of roles including a coach, companion, and confidant; (2) amplify human-to-human connection by supporting peer relationships; (3) account for data privacy and device ownership. Design materials are available in open-access, contributing to best practices for the field of Human-Robot Interaction.},
  journal      = {2022 31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  author       = {Alves-Oliveira, Patricia and Bjorling, Elin A. and Wiesmann, Patriya and Dwikat, Heba and Bhatia, Simran and Mihata, Kai and Cakmak, Maya}
}

@inproceedings{love2023adapting,
  author    = {Love, Rachel and Law, Edith and Cohen, Philip and Kulic, Dana},
  year      = {2023},
  month     = {08},
  pages     = {2541-2548},
  title     = {Adapting a Teachable Robot's Dialog Responses using Reinforcement Learning in Teaching Conversation},
  booktitle = {2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  doi       = {10.1109/RO-MAN57019.2023.10309622}
}

@inproceedings{love2024teachable,
  title     = {Teachable robots learn what to say: Improving child engagement during teaching interaction},
  abstract  = {Teachable robots are a promising technology to promote engagement in the classroom for young students. They are capable of displaying and adapting different social behaviours and characteristics, such as speech, gaze, and vocal pitch, to personalise the teaching interaction, and sustain interest for students over time. Research in this field shows a growing use of reinforcement learning to achieve this adaptation, however there is limited research on adaptive dialog behaviours for teachable robots. Our work proposes an adaptive dialog selection algorithm, implemented using Q-learning, which aims to personalise the dialog choices of a teachable robot in order to optimise for task engagement, measured by the time taken per teaching input, and the amount paraphrasing in the user{\textquoteright}s response. We investigate the effect of this approach in a case study with children aged 9–10 years old. The results show that this demographic responds positively to the teaching interaction, and provide useful insights into their preferences and abilities.},
  keywords  = {Adaptive Behaviours, Child-Robot Interaction (CRI), Engagement, Teachable Robots},
  author    = {Rachel Love and Cohen, {Philip R.} and Dana Kuli{\'c}},
  note      = {Publisher Copyright: {\textcopyright} The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.; International Conference on Social Robotics 2023, ICSR 2023 ; Conference date: 03-12-2023 Through 07-12-2023},
  year      = {2024},
  doi       = {10.1007/978-981-99-8718-4_3},
  language  = {English},
  isbn      = {9789819987177},
  series    = {Lecture Notes in Computer Science},
  publisher = {Springer},
  pages     = {27--37},
  editor    = {Ali, {Abdulaziz Al} and John-John Cabibihan and Nader Meskin and Silvia Rossi and Wanyue Jiang and Hongsheng He and Ge, {Shuzhi Sam}},
  booktitle = {Social Robotics - 15th International Conference, ICSR 2023 Doha, Qatar, December 3–7, 2023 Proceedings, Part II},
  url       = {https://link.springer.com/book/10.1007/978-981-99-8718-4, https://icsr23.qa/}
}

@inproceedings{rose2019participatory,
  author    = {Emma J. Rose and Elin Björling and Maya Cakmak},
  title     = {Participatory design with teens: A social robot design challenge},
  booktitle = {Proceedings of the 18th ACM International Conference on Interaction Design and Children (IDC '19)},
  year      = {2019},
  pages     = {6},
  address   = {Boise, ID, USA},
  publisher = {ACM},
  doi       = {10.1145/3311927.3325304},
  url       = {https://doi.org/10.1145/3311927.3325304}
}

@article{rietz2021woz4uPepper,
  author   = {Rietz, Finn  and Sutherland, Alexander  and Bensch, Suna  and Wermter, Stefan  and Hellström, Thomas },
  title    = {WoZ4U: An Open-Source Wizard-of-Oz Interface for Easy, Efficient and Robust HRI Experiments},
  journal  = {Frontiers in Robotics and AI},
  volume   = {Volume 8 - 2021},
  year     = {2021},
  url      = {https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2021.668057},
  doi      = {10.3389/frobt.2021.668057},
  issn     = {2296-9144},
  abstract = {<p>Wizard-of-Oz experiments play a vital role in Human-Robot Interaction (HRI), as they allow for quick and simple hypothesis testing. Still, a publicly available general tool to conduct such experiments is currently not available in the research community, and researchers often develop and implement their own tools, customized for each individual experiment. Besides being inefficient in terms of programming efforts, this also makes it harder for non-technical researchers to conduct Wizard-of-Oz experiments. In this paper, we present a general and easy-to-use tool for the Pepper robot, one of the most commonly used robots in this context. While we provide the concrete interface for Pepper robots only, the system architecture is independent of the type of robot and can be adapted for other robots. A configuration file, which saves experiment-specific parameters, enables a quick setup for reproducible and repeatable Wizard-of-Oz experiments. A central server provides a graphical interface <italic>via</italic> a browser while handling the mapping of user input to actions on the robot. In our interface, keyboard shortcuts may be assigned to phrases, gestures, and composite behaviors to simplify and speed up control of the robot. The interface is lightweight and independent of the operating system. Our initial tests confirm that the system is functional, flexible, and easy to use. The interface, including source code, is made commonly available, and we hope that it will be useful for researchers with any background who want to conduct HRI experiments.</p>}
}

@inproceedings{weiss2010userWOZ,
  author    = {Weiss, Astrid and Bernhaupt, Regina and Dürnberger, Daniel and Altmaninger, M. and Buchner, Roland and Tscheligi, M.},
  title     = {User experience evaluation with a Wizard of Oz approach: Technical and methodological considerations},
  booktitle = {Humanoid Robots, 2009. Humanoids 2009. 9th IEEE-RAS International Conference on},
  year      = {2010},
  month     = {01},
  pages     = {303--308},
  doi       = {10.1109/ICHR.2009.5379559},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/document/5379559}
}

@article{SCHOONDERWOERD2022102831,
  title    = {Design patterns for human-AI co-learning: A wizard-of-Oz evaluation in an urban-search-and-rescue task},
  journal  = {International Journal of Human-Computer Studies},
  volume   = {164},
  pages    = {102831},
  year     = {2022},
  issn     = {1071-5819},
  doi      = {https://doi.org/10.1016/j.ijhcs.2022.102831},
  url      = {https://www.sciencedirect.com/science/article/pii/S107158192200060X},
  author   = {Tjeerd A.J. Schoonderwoerd and Emma M. van Zoelen and Karel van den Bosch and Mark A. Neerincx},
  keywords = {Human-AI co-learning, Human-AI collaboration, Design patterns, Learning design patterns, Urban-search-and-rescue, Wizard-of-Oz study},
  abstract = {The rapid advancement of technology empowered by artificial intelligence is believed to intensify the collaboration between humans and AI as team partners. Successful collaboration requires partners to learn about each other and about the task. This human-AI co-learning can be achieved by presenting situations that enable partners to share knowledge and experiences. In this paper we describe the development and implementation of a task context and procedures for studying co-learning. More specifically, we designed specific sequences of interactions that aim to initiate and facilitate the co-learning process. The effects of these interventions on learning were evaluated in an experiment, using a simplified virtual urban-search-and-rescue task for a human-robot team. The human participants performed a victim rescue- and evacuation mission in collaboration with a wizard-of-Oz (i.e., a confederate of the experimenter who executed the robot-behavior consistent with an ontology-based AI-model). The designed interaction sequences, formulated as Learning Design Patterns (LDPs), were intended to bring about co-learning. Results show that LDPs support the humans understanding and awareness of their robot partner and of the teamwork. No effects were found on collaboration fluency, nor on team performance. Results are used to discuss the importance of co-learning, the challenges of designing human-AI team tasks for research into this phenomenon, and the conditions under which co-learning is likely to be successful. The study contributes to our understanding of how humans learn with and from AI-partners, and our propositions for designing intentional learning (LDPs) provide directions for applications in future human-AI teams.}
}

@misc{pepper_robot,
  author       = {{SoftBank Robotics}},
  title        = {Pepper -- The Humanoid Robot},
  year         = {2014},
  howpublished = {\url{https://us.softbankrobotics.com/pepper}},
  note         = {Accessed: 2025-06-12}
}

@misc{nao_robot,
  author       = {{Aldebaran Robotics}},
  title        = {NAO -- The Humanoid Robot},
  year         = {2008},
  howpublished = {\url{https://aldebaran.com/en/nao6/}},
  note         = {Accessed: 2025-06-12}
}